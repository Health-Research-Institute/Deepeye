{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54872852",
   "metadata": {},
   "source": [
    "# DenseNet Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0adc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import os.path\n",
    "from helperFunctions import tile\n",
    "from analysisFunctions import compute_score_with_logits\n",
    "from dataClasses import DataPreprocessing\n",
    "from dataClasses import DenseNet121\n",
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7c9c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Check if PyTorch has access to MPS (Metal Performance Shader, Apple's GPU architecture)\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Data Preprocessing \n",
    "data = DataPreprocessing()\n",
    "\n",
    "trainMode = eval(os.getenv(\"trainMode\"))\n",
    "if trainMode:\n",
    "    trainSize = len(data) \n",
    "    testSize = 0\n",
    "    print('Train Images: ', trainSize)\n",
    "else: \n",
    "    trainSize = 0\n",
    "    testSize = len(data)\n",
    "    print('Test Images: ', testSize) \n",
    "\n",
    "\n",
    "\n",
    "train_set, test_set = random_split(data, [trainSize, testSize])\n",
    "\n",
    "if trainMode:\n",
    "    trainloader = torch.utils.data.DataLoader(train_set, batch_size=2, shuffle=False, num_workers=0)\n",
    "else: \n",
    "    testloader = torch.utils.data.DataLoader(test_set, batch_size=1, shuffle=False)\n",
    "\n",
    "if device == \"mps\":\n",
    "    model = DenseNet121().to(device)\n",
    "    model = nn.DataParallel(model).to(device)\n",
    "elif device == \"cuda\":\n",
    "    model = DenseNet121().cuda()\n",
    "    model = nn.DataParallel(model).cuda()\n",
    "else :\n",
    "    model = DenseNet121()\n",
    "    model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664ada8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%%time\n",
    "\n",
    "#parameters to save/load models\n",
    "trainMode = eval(os.getenv('trainMode'))\n",
    "if trainMode:\n",
    "    saveModel = os.getenv('saveModel')\n",
    "else:\n",
    "    saveModel = 'False'\n",
    "\n",
    "modelPath = os.getenv('SAVE_LOAD_MODEL_PATH')\n",
    "downImageSize = os.getenv('downImageSize')\n",
    "nClasses = os.getenv('nClasses')\n",
    "modelFname = \"dense\" + str(nClasses) + \"class\" + str(downImageSize) + \"pix.pt\"\n",
    "modelPathFile = modelPath + modelFname\n",
    "\n",
    "if trainMode: \n",
    "\n",
    "    #INITIAL GUESS FROM PREVIOUSLY TRAINED MODEL\n",
    "    if os.path.isfile(modelPathFile):\n",
    "        model = torch.load(modelPathFile)\n",
    "    else:\n",
    "        pass \n",
    "\n",
    "\n",
    "    logPathFileE = modelPath + \"logEpochs.csv\"\n",
    "    if os.path.isfile(logPathFileE):\n",
    "        os.remove(logPathFileE)\n",
    "        print (' log deleted')\n",
    "    else:\n",
    "        print ('log not found')\n",
    "    logFileE = open(logPathFileE, \"a\")    \n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)  # RMSprop, Adam\n",
    "\n",
    "    nEpochs = eval(os.getenv(\"nEpochs\"))\n",
    "    useImLevels = eval(os.getenv(\"useImLevels\"))\n",
    "\n",
    "    for epoch in range(nEpochs): #loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0 \n",
    "        for i, (images, labels, image_names) in enumerate(trainloader, 0): # get the inputs; data is a list of [images, labels]\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if device == \"mps\":\n",
    "                images = images.to(device)\n",
    "                labels = tile(labels, 0, useImLevels).to(device) #duplicate for each crop the label \n",
    "            elif device == \"cuda\":\n",
    "                images = images.cuda()\n",
    "                labels = tile(labels, 0, useImLevels).cuda()\n",
    "            else:\n",
    "                labels = tile(labels, 0, useImLevels)\n",
    "        \n",
    "            #format input\n",
    "            n_batches, n_crops, channels, height, width = images.size()\n",
    "            image_batch = torch.autograd.Variable(images.view(-1, channels, height, width)) \n",
    "            \n",
    "            # forward + backward + optimize\n",
    "            outputs = model(image_batch)\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            correct += compute_score_with_logits(outputs, labels, device).sum()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        print('Epoch: %d, loss: %.3f, Accuracy: %.3f' %\n",
    "            (epoch + 1, running_loss, 100 * correct / total))\n",
    "\n",
    "        logEL = 'Epoch: ' + str(epoch +1) + ' Loss: ' + str(running_loss)\n",
    "\n",
    "        logFileE.write(logEL + ' Accuracy: ' + str(100 * correct / total ) + \"\\n\")\n",
    "\n",
    "    print('Finished Training')\n",
    "    logFileE.close()\n",
    "    if saveModel: \n",
    "        torch.save(model, modelPathFile)\n",
    "        \n",
    "#load the model when doing only testing\n",
    "else: \n",
    "    model = torch.load(modelPathFile)\n",
    "\n",
    "#model evaluation\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69071305",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 56\u001b[0m\n\u001b[0;32m     54\u001b[0m fitN \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(nCl)\n\u001b[0;32m     55\u001b[0m \u001b[39m#find maximum probability index \u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m mpi \u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39margmax(prob, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m#8-element vector w highest prob\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(nCl):\n\u001b[0;32m     59\u001b[0m      fitN[j] \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(np\u001b[39m.\u001b[39mequal(mpi, j))\n",
      "Cell \u001b[1;32mIn[6], line 56\u001b[0m\n\u001b[0;32m     54\u001b[0m fitN \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(nCl)\n\u001b[0;32m     55\u001b[0m \u001b[39m#find maximum probability index \u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m mpi \u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39margmax(prob, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m#8-element vector w highest prob\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(nCl):\n\u001b[0;32m     59\u001b[0m      fitN[j] \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(np\u001b[39m.\u001b[39mequal(mpi, j))\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2069\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[0;32m   2072\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   2074\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2075\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2103\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_input_hook()\n\u001b[0;32m   2105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2106\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[0;32m   2108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n\u001b[0;32m   2110\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#if useCalcModel:\n",
    "#    model = torch.load('model.pth')\n",
    "correct = 0\n",
    "total = 0\n",
    "useImLevels = eval(os.getenv(\"useImLevels\"))\n",
    "perfect8 = 0\n",
    "sevenLev = 0\n",
    "sixL = 0\n",
    "problem = 0\n",
    "normWArt =0\n",
    "sickAsNorm = 0\n",
    "wrongMajor = 0\n",
    "multiDes = 0\n",
    "normAsSick = 0\n",
    "vovaAcc = 0\n",
    "newAcc = 0\n",
    "\n",
    "modelPath = os.getenv('SAVE_LOAD_MODEL_PATH')\n",
    "downImageSize = os.getenv('downImageSize')\n",
    "\n",
    "logFname = \"log\" + str(nClasses) + \"class\" + str(downImageSize) + \".csv\"\n",
    "logPathFile = modelPath + logFname\n",
    "\n",
    "if os.path.isfile(logPathFile):\n",
    "    os.remove(logPathFile)\n",
    "    print (' log deleted')\n",
    "else:\n",
    "    print ('log not found')\n",
    "\n",
    "logFile = open(logPathFile, \"a\")\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (images, labels, image_names) in enumerate(testloader, 0):\n",
    "        if device == \"mps\":\n",
    "            images = images.to(device)\n",
    "            labels = tile(labels, 0, useImLevels).to(device)\n",
    "        elif device == \"cuda\":\n",
    "            images = images.cuda()\n",
    "            labels = tile(labels, 0, useImLevels).cuda() \n",
    "        else:\n",
    "            labels = tile(labels, 0, useImLevels)\n",
    "        n_batches, n_crops, channels, height, width = images.size()\n",
    "        image_batch = torch.autograd.Variable(images.view(-1, channels, height, width))\n",
    "      \n",
    "        outputs = model(image_batch)\n",
    "        prob = outputs.cpu().numpy()\n",
    "        prob = np.round(100*prob)/100\n",
    "\n",
    "        detClass = np.argmax(sum(np.floor(2*prob)))\n",
    "      \n",
    "        nCl = len(prob[0])\n",
    "        #initialize probability scorer\n",
    "        fitN = np.zeros(nCl)\n",
    "        #find maximum probability index \n",
    "        mpi =np.argmax(prob, axis=-1) #8-element vector w highest prob\n",
    "\n",
    "        for j in range(nCl):\n",
    "             fitN[j] = sum(np.equal(mpi, j))\n",
    "        labelIs = np.argmax(fitN)\n",
    "        labelWas = np.argmax(labels[0].cpu().numpy())\n",
    "        logString0 =  image_names[0][0].split(\"_1_\")[0] + \" L is: \" + str(labelIs) + \" L was: \" + str(labelWas)\n",
    "        logString1 = logString0 +  \" Fit: \" + str(fitN.astype(int))\n",
    "       \n",
    "        # Print all image content\n",
    "        # print(logString1)\n",
    "        if (labelIs == labelWas):\n",
    "            vovaAcc = vovaAcc +1\n",
    "\n",
    "        if (labelWas == detClass):\n",
    "            newAcc = newAcc +1 \n",
    "\n",
    "\n",
    "\n",
    "        # Log only problematic Images:\n",
    "        if (max(fitN) == 8) and (labelIs == labelWas):\n",
    "            perfect8 = perfect8 + 1\n",
    "        elif (max(fitN) == 7) and (labelIs == labelWas):\n",
    "            sevenLev = sevenLev + 1\n",
    "        elif (max(fitN) > 4) and (labelIs == labelWas) and (labelIs== nCl- 1):\n",
    "            sevenLev = sevenLev + 1\n",
    "        elif (max(fitN) > 4) and (labelIs == labelWas):\n",
    "            sixL = sixL + 1\n",
    "            logFile.write('Minor Second: ' + logString1 + \"\\n\")\n",
    "        elif (fitN[nCl-1] > 2) and (labelWas == nCl-1):\n",
    "            normWArt = normWArt + 1\n",
    "            logFile.write('Likely Normal w Artifact : ' + logString1 + \"\\n\")\n",
    "        elif (fitN[nCl-1] > 3) and (labelWas < nCl-1):\n",
    "            sickAsNorm = sickAsNorm + 1\n",
    "            logFile.write('PROBLEM: Sick as Normal : ' + logString1 + \"\\n\")\n",
    "            print('PROBLEM: Sick as Normal : ' + logString1)\n",
    "        elif (labelWas == nCl-1) and (labelWas !=labelIs) and (fitN[nCl-1] < 3):\n",
    "            normAsSick= normAsSick + 1\n",
    "            logFile.write('Doctor look: Normal as Sick : ' + logString1 + \"\\n\")\n",
    "            print('Doctor look: Normal as Sick : ' + logString1)\n",
    "        \n",
    "        elif (max(fitN) > 4) and (labelIs != labelWas):\n",
    "            wrongMajor = wrongMajor + 1\n",
    "            logFile.write('Problem: Wrong Major Diagnosys : ' + logString1 + \"\\n\")\n",
    "            #print('Problem: Wrong Major Diagnosys : ' + logString1)\n",
    "        elif (max(fitN) < 5) and (labelWas < nCl-1):\n",
    "            multiDes = multiDes + 1\n",
    "            logFile.write('Doctor look: Multi Diseases : ' + logString1 + \"\\n\")\n",
    "            #print('Doctor look: Multi Diseases : ' + logString1)\n",
    "        else: # Max fit < 7\n",
    "            problem = problem + 1\n",
    "            logFile.write('Unknown Problem: ' + logString1 + \"\\n\")\n",
    "            print('Unknown Problem: ' + logString1)\n",
    "\n",
    "        fitScore = compute_score_with_logits(outputs, labels, device).sum()\n",
    "        correct += fitScore.item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "logFile.close()\n",
    "\n",
    "print('newAcc: ', newAcc/len(testloader))\n",
    "\n",
    "print('Correct', correct)\n",
    "print('Total', total)\n",
    "print('vovaAcc: ', vovaAcc/len(testloader))\n",
    "\n",
    "print('Total images tested: ', len(testloader))\n",
    "# print('Accuracy according to Standard Metric: %.3f' % (100 * correct / total))\n",
    "print('Single Desease/normal w High Convidence,', perfect8+sevenLev, \"Percentage\", round(10000*(perfect8+sevenLev)/len(testloader))/100, '%')\n",
    "print('Single Desease/normal may have 2nd minor,', sixL, \"Percentage\", round(10000*(sixL)/len(testloader))/100, '%')\n",
    "print('Normal with Device Artifact,', normWArt , \"Percentage\",  round(10000*(normWArt)/len(testloader))/100, '%')\n",
    "print('Problem: Wrong Major Diagnosys', wrongMajor , \"Percentage\", round(10000*(wrongMajor)/len(testloader))/100, '%')\n",
    "print('PROBLEM: Sick as Normal', sickAsNorm , \"Percentage\", round(10000*(sickAsNorm)/len(testloader))/100, '%')\n",
    "print('Doc Look: Multiple Diseases', multiDes , \"Percentage\", round(10000*(multiDes)/len(testloader))/100, '%')\n",
    "print('Doc Look: Normal as Sick', normAsSick , \"Percentage\", round(10000*(normAsSick)/len(testloader))/100, '%')\n",
    "print('Unknown Problems', problem , \"Percentage\", round(10000*(problem)/len(testloader))/100, '%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
